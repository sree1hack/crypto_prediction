{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyN0sb2KbvDVUmlUikZJaMwQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BK2CtXimCdFh","executionInfo":{"status":"ok","timestamp":1757406530229,"user_tz":-330,"elapsed":24502,"user":{"displayName":"DHANWADA SREEPAD DHANWADA SREEPAD","userId":"12549078030822633320"}},"outputId":"b01c956b-70d3-4747-e0e2-5ceed8b7c727"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["\"\"\"\n","train_lstm_crypto_colab.py\n","\n","Trains per-coin LSTM models using CSVs stored in Google Drive.\n","\n","Folder structure in Drive:\n","MyDrive/infosys/\n","    daily/   -> daily CSVs (per-coin)\n","    hourly/  -> hourly CSVs (per-coin)\n","    outputs/ -> results saved here\n","\"\"\"\n","\n","import argparse\n","import os\n","import sys\n","import glob\n","import re\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from joblib import dump\n","\n","import tensorflow as tf\n","print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n","print(\"GPU Details:\", tf.config.list_physical_devices('GPU'))\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","# -----------------------------\n","# Helpers\n","# -----------------------------\n","\n","TIMESTAMP_CANDIDATES = [\"timestamp\",\"date\",\"datetime\",\"time\"]\n","TARGET_CANDIDATES    = [\"close\",\"adj close\",\"price\",\"close_price\",\"closing price\",\"close*\"]\n","\n","def find_first_column(df: pd.DataFrame, candidates):\n","    cols_lower = {c.lower(): c for c in df.columns}\n","    for name in candidates:\n","        if name in cols_lower:\n","            return cols_lower[name]\n","    for name in candidates:\n","        base = name.replace(\"*\",\"\").strip()\n","        for c in df.columns:\n","            if c.lower().startswith(base):\n","                return c\n","    return None\n","\n","def coin_from_filename(path: str) -> str:\n","    name = os.path.splitext(os.path.basename(path))[0]\n","    name = re.sub(r'(_daily|_hourly)$', \"\", name, flags=re.IGNORECASE)\n","    return name.upper()\n","\n","def read_series(path: str, timestamp_col=None, target_col=None):\n","    df = pd.read_csv(path)\n","    if timestamp_col is None:\n","        timestamp_col = find_first_column(df, TIMESTAMP_CANDIDATES)\n","    if target_col is None:\n","        target_col = find_first_column(df, TARGET_CANDIDATES)\n","    if timestamp_col is None or target_col is None:\n","        raise ValueError(f\"Could not auto-detect timestamp/target in {path}. Columns={list(df.columns)}\")\n","    df[timestamp_col] = pd.to_datetime(df[timestamp_col], errors='coerce', infer_datetime_format=True)\n","    df = df.dropna(subset=[timestamp_col])\n","    df = df.sort_values(timestamp_col).reset_index(drop=True)\n","    s = df[target_col].astype(float).values.reshape(-1,1)\n","    ts = df[timestamp_col].values\n","    return ts, s, timestamp_col, target_col\n","\n","def make_windows(series: np.ndarray, window: int, horizon: int):\n","    X, y = [], []\n","    for i in range(len(series) - window - horizon + 1):\n","        X.append(series[i:i+window])\n","        y.append(series[i+window:i+window+horizon].ravel())\n","    return np.array(X), np.array(y)\n","\n","def train_val_test_split(X, y, val_size=0.15, test_size=0.15):\n","    n = len(X)\n","    n_test = int(n * test_size)\n","    n_val  = int((n - n_test) * val_size)\n","    train_end = n - n_test - n_val\n","    val_end   = n - n_test\n","    return X[:train_end], y[:train_end], X[train_end:val_end], y[train_end:val_end], X[val_end:], y[val_end:]\n","\n","def build_model(window: int, features: int, horizon: int, lr: float = 1e-3):\n","    model = Sequential([\n","        Input(shape=(window, features)),\n","        LSTM(64, return_sequences=True),\n","        Dropout(0.2),\n","        LSTM(32),\n","        Dense(horizon)\n","    ])\n","    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr), loss=\"mse\")\n","    return model\n","\n","def metrics_dict(y_true, y_pred, prefix=\"\"):\n","    y_true = np.asarray(y_true).ravel()\n","    y_pred = np.asarray(y_pred).ravel()\n","    if y_true.size == 0:\n","        return {f\"{prefix}RMSE\": float(\"nan\"),\n","                f\"{prefix}MAE\": float(\"nan\"),\n","                f\"{prefix}MAPE\": float(\"nan\")}\n","    mse = np.mean((y_true - y_pred) ** 2)\n","    rmse = float(np.sqrt(mse))\n","    mae = float(np.mean(np.abs(y_true - y_pred)))\n","    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n","        denom = np.clip(np.abs(y_true), 1e-8, None)\n","        mape = float(np.mean(np.abs((y_true - y_pred) / denom)) * 100.0)\n","    return {f\"{prefix}RMSE\": rmse,\n","            f\"{prefix}MAE\": mae,\n","            f\"{prefix}MAPE\": mape}\n","\n","def ensure_dir(path):\n","    os.makedirs(path, exist_ok=True)\n","\n","# -----------------------------\n","# Training routine\n","# -----------------------------\n","\n","def train_for_folder(data_dir: str, freq: str, args):\n","    if not os.path.isdir(data_dir):\n","        print(f\"[{freq}] Directory not found: {data_dir}\")\n","        return []\n","\n","    files = sorted(glob.glob(os.path.join(data_dir, args.pattern)))\n","    if not files:\n","        print(f\"[{freq}] No CSV files found in {data_dir}\")\n","        return []\n","\n","    out_model_dir = os.path.join(args.output_dir, \"models\", freq)\n","    out_scaler_dir = os.path.join(args.output_dir, \"scalers\", freq)\n","    out_pred_dir = os.path.join(args.output_dir, \"predictions\", freq)\n","    ensure_dir(out_model_dir)\n","    ensure_dir(out_scaler_dir)\n","    ensure_dir(out_pred_dir)\n","\n","    rows = []\n","    for f in files:\n","        coin = coin_from_filename(f)\n","        print(f\"[{freq}] Training {coin}...\")\n","\n","        try:\n","            ts, s, tcol, ycol = read_series(f, args.timestamp_col, args.target_col)\n","        except Exception as e:\n","            print(f\"[{freq}] {coin}: ERROR reading file -> {e}\")\n","            continue\n","\n","        scaler = MinMaxScaler()\n","        s_scaled = scaler.fit_transform(s)\n","\n","        X, y = make_windows(s_scaled, args.window, args.horizon)\n","        if len(X) < 10:\n","            print(f\"[{freq}] {coin}: not enough data. Skipping.\")\n","            continue\n","\n","        X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, args.val_size, args.test_size)\n","\n","        tf.keras.backend.clear_session()\n","        model = build_model(args.window, X.shape[-1], args.horizon, lr=args.learning_rate)\n","\n","        ckpt_path = os.path.join(out_model_dir, f\"{coin}.keras\")\n","\n","        # --- NEW: check if a saved model already exists ---\n","        if os.path.exists(ckpt_path):\n","            print(f\"[{freq}] {coin}: Resuming training from saved checkpoint...\")\n","            model = tf.keras.models.load_model(ckpt_path)\n","        else:\n","            print(f\"[{freq}] {coin}: Starting new training...\")\n","            model = build_model(args.window, X.shape[-1], args.horizon, lr=args.learning_rate)\n","\n","        callbacks = [\n","            EarlyStopping(monitor=\"val_loss\", patience=args.patience, restore_best_weights=True),\n","            ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=max(2, args.patience//2), verbose=1),\n","            ModelCheckpoint(ckpt_path, monitor=\"val_loss\", save_best_only=True, save_freq=\"epoch\")\n","        ]\n","\n","        history = model.fit(\n","            X_train, y_train,\n","            validation_data=(X_val, y_val),\n","            epochs=args.epochs,\n","            batch_size=args.batch_size,\n","            verbose=1,\n","            callbacks=callbacks\n","        )\n","\n","        def inv(pred):\n","            return np.array([scaler.inverse_transform(row.reshape(-1,1)).ravel() for row in pred])\n","\n","        y_pred_val = inv(model.predict(X_val, verbose=0))\n","        y_pred_test = inv(model.predict(X_test, verbose=0))\n","        y_val_inv, y_test_inv = inv(y_val), inv(y_test)\n","\n","        m_val  = metrics_dict(y_val_inv[:,0], y_pred_val[:,0], prefix=\"val_\")\n","        m_test = metrics_dict(y_test_inv[:,0], y_pred_test[:,0], prefix=\"test_\")\n","\n","        row = {\"freq\": freq, \"coin\": coin, \"window\": args.window, \"horizon\": args.horizon}\n","        row.update(m_val)\n","        row.update(m_test)\n","        rows.append(row)\n","\n","        dump(scaler, os.path.join(out_scaler_dir, f\"{coin}.joblib\"))\n","        pred_df = pd.DataFrame({\n","            \"set\": [\"val\"]*len(y_val_inv) + [\"test\"]*len(y_test_inv),\n","            \"y_true\": np.concatenate([y_val_inv[:,0], y_test_inv[:,0]]),\n","            \"y_pred\": np.concatenate([y_pred_val[:,0], y_pred_test[:,0]])\n","        })\n","        pred_df.to_csv(os.path.join(out_pred_dir, f\"{coin}.csv\"), index=False)\n","\n","        print(f\"[{freq}] {coin}: done. val_RMSE={m_val['val_RMSE']:.4f} test_RMSE={m_test['test_RMSE']:.4f}\")\n","\n","    if rows:\n","        metrics_dir = os.path.join(args.output_dir, \"metrics\", freq)\n","        ensure_dir(metrics_dir)\n","        pd.DataFrame(rows).to_csv(os.path.join(metrics_dir, \"metrics.csv\"), index=False)\n","        print(f\"[{freq}] Metrics saved -> {metrics_dir}/metrics.csv\")\n","\n","# -----------------------------\n","# Main\n","# -----------------------------\n","\n","def parse_args():\n","    p = argparse.ArgumentParser()\n","    # In Colab: default base = /content/drive/MyDrive/infosys\n","    base = \"/content/drive/MyDrive/infosys\"\n","    p.add_argument(\"--daily_dir\", type=str, default=os.path.join(base, \"daily\"))\n","    p.add_argument(\"--hourly_dir\", type=str, default=os.path.join(base, \"hourly\"))\n","    p.add_argument(\"--output_dir\", type=str, default=os.path.join(base, \"outputs\"))\n","    p.add_argument(\"--pattern\", type=str, default=\"*.csv\")\n","    p.add_argument(\"--timestamp_col\", type=str, default=None)\n","    p.add_argument(\"--target_col\", type=str, default=None)\n","    p.add_argument(\"--window\", type=int, default=60)\n","    p.add_argument(\"--horizon\", type=int, default=1)\n","    p.add_argument(\"--val_size\", type=float, default=0.15)\n","    p.add_argument(\"--test_size\", type=float, default=0.15)\n","    p.add_argument(\"--epochs\", type=int, default=50)\n","    p.add_argument(\"--batch_size\", type=int, default=64)\n","    p.add_argument(\"--learning_rate\", type=float, default=1e-3)\n","    p.add_argument(\"--patience\", type=int, default=5)\n","    return p.parse_args(args=[])\n","\n","def main():\n","    args = parse_args()\n","    ensure_dir(args.output_dir)\n","\n","    print(\"=== LSTM Crypto Training (Colab) ===\")\n","    print(f\"daily_dir  : {args.daily_dir}\")\n","    print(f\"hourly_dir : {args.hourly_dir}\")\n","    print(f\"output_dir : {args.output_dir}\")\n","\n","    train_for_folder(args.daily_dir, \"daily\", args)\n","    train_for_folder(args.hourly_dir, \"hourly\", args)\n","\n","    print(\"Done.\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6JFLjdUuDYlf","executionInfo":{"status":"ok","timestamp":1757409342658,"user_tz":-330,"elapsed":2792260,"user":{"displayName":"DHANWADA SREEPAD DHANWADA SREEPAD","userId":"12549078030822633320"}},"outputId":"3a033a7c-9f31-4d99-dd0b-93ce8dff920e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available: 1\n","GPU Details: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","=== LSTM Crypto Training (Colab) ===\n","daily_dir  : /content/drive/MyDrive/infosys/daily\n","hourly_dir : /content/drive/MyDrive/infosys/hourly\n","output_dir : /content/drive/MyDrive/infosys/outputs\n","[daily] Training ALL_CRYPTO_INR_HOURLY_MERGED...\n","[daily] ALL_CRYPTO_INR_HOURLY_MERGED: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 3.1250e-05\n","Epoch 2/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 3.1250e-05\n","Epoch 3/50\n","\u001b[1m354/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 3.1250e-05\n","Epoch 4/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 1.5625e-05\n","Epoch 5/50\n","\u001b[1m351/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 1.5625e-05\n","Epoch 6/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0056 - learning_rate: 7.8125e-06\n","Epoch 7/50\n","\u001b[1m355/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 0.0056 - learning_rate: 7.8125e-06\n","Epoch 8/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 3.9063e-06\n","Epoch 9/50\n","\u001b[1m355/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0018 - val_loss: 0.0056 - learning_rate: 3.9063e-06\n","Epoch 10/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 1.9531e-06\n","Epoch 11/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0019\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0019 - val_loss: 0.0056 - learning_rate: 1.9531e-06\n","Epoch 12/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 0.0017 - val_loss: 0.0056 - learning_rate: 9.7656e-07\n","Epoch 13/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0018 - val_loss: 0.0056 - learning_rate: 9.7656e-07\n","Epoch 14/50\n","\u001b[1m357/357\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0018 - val_loss: 0.0056 - learning_rate: 4.8828e-07\n","[daily] ALL_CRYPTO_INR_HOURLY_MERGED: done. val_RMSE=805321.7693 test_RMSE=1741233.5112\n","[daily] Training BINANCE_COIN_INR...\n","[daily] BINANCE_COIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.4711e-04 - val_loss: 0.0012 - learning_rate: 2.5000e-04\n","Epoch 2/50\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.8336e-04 - val_loss: 7.6909e-04 - learning_rate: 2.5000e-04\n","Epoch 3/50\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.5581e-04 - val_loss: 7.7963e-04 - learning_rate: 2.5000e-04\n","Epoch 4/50\n","\u001b[1m28/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2921e-04\n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.3260e-04 - val_loss: 8.7949e-04 - learning_rate: 2.5000e-04\n","Epoch 5/50\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2704e-04 - val_loss: 8.6920e-04 - learning_rate: 1.2500e-04\n","Epoch 6/50\n","\u001b[1m27/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7618e-04\n","Epoch 6: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.8090e-04 - val_loss: 8.3315e-04 - learning_rate: 1.2500e-04\n","Epoch 7/50\n","\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 5.9793e-04 - val_loss: 8.2721e-04 - learning_rate: 6.2500e-05\n","[daily] BINANCE_COIN_INR: done. val_RMSE=2181.8972 test_RMSE=3514.4900\n","[daily] Training BITCOIN_CASH_INR...\n","[daily] BITCOIN_CASH_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: 7.7380e-04 - val_loss: 1.1008e-04 - learning_rate: 7.8125e-06\n","Epoch 2/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.1158e-04 - val_loss: 1.1031e-04 - learning_rate: 7.8125e-06\n","Epoch 3/50\n","\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8177e-04\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 9.5711e-04 - val_loss: 1.1006e-04 - learning_rate: 7.8125e-06\n","Epoch 4/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011 - val_loss: 1.1015e-04 - learning_rate: 3.9063e-06\n","Epoch 5/50\n","\u001b[1m29/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0010\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.9158e-04 - val_loss: 1.1036e-04 - learning_rate: 3.9063e-06\n","Epoch 6/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.6370e-04 - val_loss: 1.1034e-04 - learning_rate: 1.9531e-06\n","Epoch 7/50\n","\u001b[1m28/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9106e-04\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 8.8139e-04 - val_loss: 1.1021e-04 - learning_rate: 1.9531e-06\n","Epoch 8/50\n","\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.3759e-04 - val_loss: 1.1015e-04 - learning_rate: 9.7656e-07\n","[daily] BITCOIN_CASH_INR: done. val_RMSE=3374.5969 test_RMSE=2500.3411\n","[daily] Training BITCOIN_INR...\n","[daily] BITCOIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 7.4094e-05 - val_loss: 3.1025e-04 - learning_rate: 3.9063e-06\n","Epoch 2/50\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.6226e-05 - val_loss: 3.1015e-04 - learning_rate: 3.9063e-06\n","Epoch 3/50\n","\u001b[1m57/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.2225e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.2585e-05 - val_loss: 3.1090e-04 - learning_rate: 3.9063e-06\n","Epoch 4/50\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.8501e-05 - val_loss: 3.1077e-04 - learning_rate: 1.9531e-06\n","Epoch 5/50\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5654e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 6.5743e-05 - val_loss: 3.1034e-04 - learning_rate: 1.9531e-06\n","Epoch 6/50\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 5.9607e-05 - val_loss: 3.1033e-04 - learning_rate: 9.7656e-07\n","Epoch 7/50\n","\u001b[1m60/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.9549e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 8.8975e-05 - val_loss: 3.1045e-04 - learning_rate: 9.7656e-07\n","[daily] BITCOIN_INR: done. val_RMSE=189869.4095 test_RMSE=432837.0837\n","[daily] Training CHAINLINK_COIN_INR...\n","[daily] CHAINLINK_COIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: 0.0011 - val_loss: 4.6931e-04 - learning_rate: 2.4414e-07\n","Epoch 2/50\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 4.6931e-04 - learning_rate: 2.4414e-07\n","Epoch 3/50\n","\u001b[1m29/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0010\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0010 - val_loss: 4.6935e-04 - learning_rate: 2.4414e-07\n","Epoch 4/50\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0014 - val_loss: 4.6934e-04 - learning_rate: 1.2207e-07\n","Epoch 5/50\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0010\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0010 - val_loss: 4.6931e-04 - learning_rate: 1.2207e-07\n","Epoch 6/50\n","\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 9.4829e-04 - val_loss: 4.6932e-04 - learning_rate: 6.1035e-08\n","[daily] CHAINLINK_COIN_INR: done. val_RMSE=98.9920 test_RMSE=149.3747\n","[daily] Training DOGECOIN_INR...\n","[daily] DOGECOIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0016 - val_loss: 0.0023 - learning_rate: 0.0010\n","Epoch 2/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0025 - val_loss: 0.0017 - learning_rate: 0.0010\n","Epoch 3/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0014 - val_loss: 0.0017 - learning_rate: 0.0010\n","Epoch 4/50\n","\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012    \n","Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0017 - learning_rate: 0.0010\n","Epoch 5/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0015 - learning_rate: 5.0000e-04\n","Epoch 6/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0016 - val_loss: 0.0018 - learning_rate: 5.0000e-04\n","Epoch 7/50\n","\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 9.8573e-04\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0011 - val_loss: 0.0015 - learning_rate: 5.0000e-04\n","Epoch 8/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0016 - val_loss: 0.0014 - learning_rate: 2.5000e-04\n","Epoch 9/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 0.0015 - learning_rate: 2.5000e-04\n","Epoch 10/50\n","\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0013 - val_loss: 0.0014 - learning_rate: 2.5000e-04\n","Epoch 11/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0012 - val_loss: 0.0015 - learning_rate: 1.2500e-04\n","Epoch 12/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4597e-04\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.6479e-04 - val_loss: 0.0014 - learning_rate: 1.2500e-04\n","Epoch 13/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0010 - val_loss: 0.0014 - learning_rate: 6.2500e-05\n","Epoch 14/50\n","\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012 - val_loss: 0.0013 - learning_rate: 6.2500e-05\n","Epoch 15/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0014 - val_loss: 0.0014 - learning_rate: 3.1250e-05\n","Epoch 16/50\n","\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0015 - val_loss: 0.0014 - learning_rate: 3.1250e-05\n","Epoch 17/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0013 - val_loss: 0.0014 - learning_rate: 1.5625e-05\n","Epoch 18/50\n","\u001b[1m15/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: 0.0014 - val_loss: 0.0014 - learning_rate: 1.5625e-05\n","Epoch 19/50\n","\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0016 - val_loss: 0.0014 - learning_rate: 7.8125e-06\n","[daily] DOGECOIN_INR: done. val_RMSE=2.1620 test_RMSE=1.5882\n","[daily] Training ETHEREUM_INR...\n","[daily] ETHEREUM_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 6.4533e-04 - val_loss: 3.4982e-04 - learning_rate: 3.9063e-06\n","Epoch 2/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.6951e-04 - val_loss: 3.4885e-04 - learning_rate: 3.9063e-06\n","Epoch 3/50\n","\u001b[1m36/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.0953e-04\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.0405e-04 - val_loss: 3.4961e-04 - learning_rate: 3.9063e-06\n","Epoch 4/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 7.2296e-04 - val_loss: 3.4895e-04 - learning_rate: 1.9531e-06\n","Epoch 5/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.7070e-04\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.7058e-04 - val_loss: 3.4943e-04 - learning_rate: 1.9531e-06\n","Epoch 6/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9809e-04 - val_loss: 3.4934e-04 - learning_rate: 9.7656e-07\n","Epoch 7/50\n","\u001b[1m35/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.0952e-04\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.1699e-04 - val_loss: 3.4883e-04 - learning_rate: 9.7656e-07\n","Epoch 8/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.6173e-04 - val_loss: 3.4884e-04 - learning_rate: 4.8828e-07\n","Epoch 9/50\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.9093e-04\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.8615e-04 - val_loss: 3.4910e-04 - learning_rate: 4.8828e-07\n","Epoch 10/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.2248e-04 - val_loss: 3.4898e-04 - learning_rate: 2.4414e-07\n","Epoch 11/50\n","\u001b[1m40/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.7120e-04\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.7034e-04 - val_loss: 3.4898e-04 - learning_rate: 2.4414e-07\n","Epoch 12/50\n","\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 6.5062e-04 - val_loss: 3.4897e-04 - learning_rate: 1.2207e-07\n","[daily] ETHEREUM_INR: done. val_RMSE=7886.0674 test_RMSE=16556.9889\n","[daily] Training LITECOIN_INR...\n","[daily] LITECOIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 7.0228e-04 - val_loss: 2.2500e-04 - learning_rate: 6.2500e-05\n","Epoch 2/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.5752e-04 - val_loss: 1.9823e-04 - learning_rate: 6.2500e-05\n","Epoch 3/50\n","\u001b[1m46/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.6264e-04\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6.6945e-04 - val_loss: 2.2471e-04 - learning_rate: 6.2500e-05\n","Epoch 4/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0025e-04 - val_loss: 1.7940e-04 - learning_rate: 3.1250e-05\n","Epoch 5/50\n","\u001b[1m47/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 6.4372e-04\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4813e-04 - val_loss: 2.1153e-04 - learning_rate: 3.1250e-05\n","Epoch 6/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9431e-04 - val_loss: 1.9238e-04 - learning_rate: 1.5625e-05\n","Epoch 7/50\n","\u001b[1m46/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.5494e-04\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5087e-04 - val_loss: 1.9239e-04 - learning_rate: 1.5625e-05\n","Epoch 8/50\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1385e-04 - val_loss: 1.9407e-04 - learning_rate: 7.8125e-06\n","Epoch 9/50\n","\u001b[1m48/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 7.2276e-04\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2109e-04 - val_loss: 1.9804e-04 - learning_rate: 7.8125e-06\n","[daily] LITECOIN_INR: done. val_RMSE=453.1135 test_RMSE=538.1002\n","[daily] Training POLKADOT_INR...\n","[daily] POLKADOT_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0017 - val_loss: 1.1544e-04 - learning_rate: 2.5000e-04\n","Epoch 2/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0022 - val_loss: 1.3819e-04 - learning_rate: 2.5000e-04\n","Epoch 3/50\n","\u001b[1m20/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0018 - val_loss: 1.1297e-04 - learning_rate: 2.5000e-04\n","Epoch 4/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 1.7226e-04 - learning_rate: 1.2500e-04\n","Epoch 5/50\n","\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0015 - val_loss: 1.1866e-04 - learning_rate: 1.2500e-04\n","Epoch 6/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014 - val_loss: 1.3007e-04 - learning_rate: 6.2500e-05\n","Epoch 7/50\n","\u001b[1m21/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0018\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0018 - val_loss: 1.4051e-04 - learning_rate: 6.2500e-05\n","Epoch 8/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0016 - val_loss: 1.3747e-04 - learning_rate: 3.1250e-05\n","[daily] POLKADOT_INR: done. val_RMSE=49.3128 test_RMSE=56.7086\n","[daily] Training POLYGON_INR...\n","[daily] POLYGON_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.0014 - val_loss: 3.8805e-04 - learning_rate: 6.2500e-05\n","Epoch 2/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0016 - val_loss: 4.2521e-04 - learning_rate: 6.2500e-05\n","Epoch 3/50\n","\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0017\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - loss: 0.0017 - val_loss: 3.5744e-04 - learning_rate: 6.2500e-05\n","Epoch 4/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0013 - val_loss: 4.0316e-04 - learning_rate: 3.1250e-05\n","Epoch 5/50\n","\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0017 - val_loss: 4.1605e-04 - learning_rate: 3.1250e-05\n","Epoch 6/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 - val_loss: 3.9629e-04 - learning_rate: 1.5625e-05\n","Epoch 7/50\n","\u001b[1m22/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0013\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013 - val_loss: 3.9240e-04 - learning_rate: 1.5625e-05\n","Epoch 8/50\n","\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016 - val_loss: 3.8743e-04 - learning_rate: 7.8125e-06\n","[daily] POLYGON_INR: done. val_RMSE=4.7399 test_RMSE=3.1534\n","[daily] Training RIPPLE_INR...\n","[daily] RIPPLE_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 6.6408e-04 - val_loss: 1.4230e-04 - learning_rate: 6.2500e-05\n","Epoch 2/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 6.9948e-04 - val_loss: 1.3463e-04 - learning_rate: 6.2500e-05\n","Epoch 3/50\n","\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.4954e-04\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.5149e-04 - val_loss: 1.4603e-04 - learning_rate: 6.2500e-05\n","Epoch 4/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 6.7306e-04 - val_loss: 1.3427e-04 - learning_rate: 3.1250e-05\n","Epoch 5/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.5679e-04\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.5767e-04 - val_loss: 1.3441e-04 - learning_rate: 3.1250e-05\n","Epoch 6/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.4145e-04 - val_loss: 1.3407e-04 - learning_rate: 1.5625e-05\n","Epoch 7/50\n","\u001b[1m29/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9924e-04\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 6.1776e-04 - val_loss: 1.3196e-04 - learning_rate: 1.5625e-05\n","Epoch 8/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 6.7647e-04 - val_loss: 1.3335e-04 - learning_rate: 7.8125e-06\n","Epoch 9/50\n","\u001b[1m31/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 5.8487e-04\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 5.9616e-04 - val_loss: 1.3673e-04 - learning_rate: 7.8125e-06\n","Epoch 10/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 6.8312e-04 - val_loss: 1.3391e-04 - learning_rate: 3.9063e-06\n","Epoch 11/50\n","\u001b[1m34/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.8841e-04\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5.9287e-04 - val_loss: 1.3365e-04 - learning_rate: 3.9063e-06\n","Epoch 12/50\n","\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 5.9165e-04 - val_loss: 1.3375e-04 - learning_rate: 1.9531e-06\n","[daily] RIPPLE_INR: done. val_RMSE=3.5479 test_RMSE=29.1341\n","[daily] Metrics saved -> /content/drive/MyDrive/infosys/outputs/metrics/daily/metrics.csv\n","[hourly] Training ALL_CRYPTO_INR_HOURLY_MERGED...\n","[hourly] ALL_CRYPTO_INR_HOURLY_MERGED: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0091 - learning_rate: 7.8125e-06\n","Epoch 2/50\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 7.8125e-06\n","Epoch 3/50\n","\u001b[1m8476/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 7.8125e-06\n","Epoch 4/50\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 3.9063e-06\n","Epoch 5/50\n","\u001b[1m8474/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 3.9063e-06\n","Epoch 6/50\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 10ms/step - loss: 0.0028 - val_loss: 0.0090 - learning_rate: 1.9531e-06\n","Epoch 7/50\n","\u001b[1m8477/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 10ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 1.9531e-06\n","Epoch 8/50\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 9.7656e-07\n","Epoch 9/50\n","\u001b[1m8475/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 9.7656e-07\n","Epoch 10/50\n","\u001b[1m8480/8480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 9ms/step - loss: 0.0029 - val_loss: 0.0090 - learning_rate: 4.8828e-07\n","[hourly] ALL_CRYPTO_INR_HOURLY_MERGED: done. val_RMSE=1028672.9607 test_RMSE=2160430.9332\n","[hourly] Training BINANCE_INR...\n","[hourly] BINANCE_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 2.4519e-05 - val_loss: 1.8320e-05 - learning_rate: 2.4414e-07\n","Epoch 2/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.4335e-05 - val_loss: 1.8427e-05 - learning_rate: 2.4414e-07\n","Epoch 3/50\n","\u001b[1m778/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4837e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.4837e-05 - val_loss: 1.8346e-05 - learning_rate: 2.4414e-07\n","Epoch 4/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.4204e-05 - val_loss: 1.8354e-05 - learning_rate: 1.2207e-07\n","Epoch 5/50\n","\u001b[1m780/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4664e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.4663e-05 - val_loss: 1.8293e-05 - learning_rate: 1.2207e-07\n","Epoch 6/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.4615e-05 - val_loss: 1.8308e-05 - learning_rate: 6.1035e-08\n","Epoch 7/50\n","\u001b[1m778/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5366e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 2.5362e-05 - val_loss: 1.8291e-05 - learning_rate: 6.1035e-08\n","Epoch 8/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.3998e-05 - val_loss: 1.8303e-05 - learning_rate: 3.0518e-08\n","Epoch 9/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3713e-05\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.3714e-05 - val_loss: 1.8325e-05 - learning_rate: 3.0518e-08\n","Epoch 10/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.4837e-05 - val_loss: 1.8309e-05 - learning_rate: 1.5259e-08\n","Epoch 11/50\n","\u001b[1m780/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4066e-05\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.4068e-05 - val_loss: 1.8308e-05 - learning_rate: 1.5259e-08\n","Epoch 12/50\n","\u001b[1m781/781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.4669e-05 - val_loss: 1.8313e-05 - learning_rate: 7.6294e-09\n","[hourly] BINANCE_INR: done. val_RMSE=336.4826 test_RMSE=504.2625\n","[hourly] Training BITCOIN_CASH_INR...\n","[hourly] BITCOIN_CASH_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 3.4512e-05 - val_loss: 7.0792e-06 - learning_rate: 1.2500e-04\n","Epoch 2/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 3.0827e-05 - val_loss: 2.1238e-06 - learning_rate: 1.2500e-04\n","Epoch 3/50\n","\u001b[1m797/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3668e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 3.3649e-05 - val_loss: 2.9736e-06 - learning_rate: 1.2500e-04\n","Epoch 4/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.9676e-05 - val_loss: 1.9458e-06 - learning_rate: 6.2500e-05\n","Epoch 5/50\n","\u001b[1m800/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9327e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.9328e-05 - val_loss: 2.0710e-06 - learning_rate: 6.2500e-05\n","Epoch 6/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 3.0268e-05 - val_loss: 1.7313e-06 - learning_rate: 3.1250e-05\n","Epoch 7/50\n","\u001b[1m797/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.0248e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 3.0239e-05 - val_loss: 1.8493e-06 - learning_rate: 3.1250e-05\n","Epoch 8/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.9343e-05 - val_loss: 1.8471e-06 - learning_rate: 1.5625e-05\n","Epoch 9/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7807e-05\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.7807e-05 - val_loss: 1.7063e-06 - learning_rate: 1.5625e-05\n","Epoch 10/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.7425e-05 - val_loss: 1.7749e-06 - learning_rate: 7.8125e-06\n","Epoch 11/50\n","\u001b[1m796/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.8267e-05\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 2.8268e-05 - val_loss: 1.6870e-06 - learning_rate: 7.8125e-06\n","Epoch 12/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.8409e-05 - val_loss: 1.6892e-06 - learning_rate: 3.9063e-06\n","Epoch 13/50\n","\u001b[1m797/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.7449e-05\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.7449e-05 - val_loss: 1.7114e-06 - learning_rate: 3.9063e-06\n","Epoch 14/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - loss: 2.8478e-05 - val_loss: 1.7186e-06 - learning_rate: 1.9531e-06\n","Epoch 15/50\n","\u001b[1m797/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6825e-05\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 2.6824e-05 - val_loss: 1.6899e-06 - learning_rate: 1.9531e-06\n","Epoch 16/50\n","\u001b[1m801/801\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.7585e-05 - val_loss: 1.7086e-06 - learning_rate: 9.7656e-07\n","[hourly] BITCOIN_CASH_INR: done. val_RMSE=449.0856 test_RMSE=459.3850\n","[hourly] Training BITCOIN_INR...\n","[hourly] BITCOIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - loss: 7.6273e-06 - val_loss: 1.3827e-05 - learning_rate: 5.0000e-04\n","Epoch 2/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 7.0735e-06 - val_loss: 1.3250e-05 - learning_rate: 5.0000e-04\n","Epoch 3/50\n","\u001b[1m1456/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.0685e-06\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 7.0686e-06 - val_loss: 1.2538e-05 - learning_rate: 5.0000e-04\n","Epoch 4/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 5.3012e-06 - val_loss: 9.4170e-06 - learning_rate: 2.5000e-04\n","Epoch 5/50\n","\u001b[1m1457/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2839e-06\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 5.2838e-06 - val_loss: 1.0154e-05 - learning_rate: 2.5000e-04\n","Epoch 6/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 4.4832e-06 - val_loss: 9.1360e-06 - learning_rate: 1.2500e-04\n","Epoch 7/50\n","\u001b[1m1458/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.6846e-06\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 4.6845e-06 - val_loss: 1.1968e-05 - learning_rate: 1.2500e-04\n","Epoch 8/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 3.9633e-06 - val_loss: 8.4317e-06 - learning_rate: 6.2500e-05\n","Epoch 9/50\n","\u001b[1m1457/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8992e-06\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 9ms/step - loss: 3.8994e-06 - val_loss: 9.0970e-06 - learning_rate: 6.2500e-05\n","Epoch 10/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 3.8024e-06 - val_loss: 9.6823e-06 - learning_rate: 3.1250e-05\n","Epoch 11/50\n","\u001b[1m1458/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5596e-06\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - loss: 3.5596e-06 - val_loss: 1.0279e-05 - learning_rate: 3.1250e-05\n","Epoch 12/50\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 9ms/step - loss: 3.6319e-06 - val_loss: 9.5282e-06 - learning_rate: 1.5625e-05\n","Epoch 13/50\n","\u001b[1m1456/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3974e-06\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m1459/1459\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 10ms/step - loss: 3.3976e-06 - val_loss: 1.0165e-05 - learning_rate: 1.5625e-05\n","[hourly] BITCOIN_INR: done. val_RMSE=31443.3658 test_RMSE=240366.8869\n","[hourly] Training CHAINLINK_INR...\n","[hourly] CHAINLINK_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 4.1481e-05 - val_loss: 1.5253e-05 - learning_rate: 2.4414e-07\n","Epoch 2/50\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 4.3806e-05 - val_loss: 1.5276e-05 - learning_rate: 2.4414e-07\n","Epoch 3/50\n","\u001b[1m737/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.2392e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 4.2396e-05 - val_loss: 1.5279e-05 - learning_rate: 2.4414e-07\n","Epoch 4/50\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 4.4416e-05 - val_loss: 1.5266e-05 - learning_rate: 1.2207e-07\n","Epoch 5/50\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.3121e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 4.3120e-05 - val_loss: 1.5288e-05 - learning_rate: 1.2207e-07\n","Epoch 6/50\n","\u001b[1m739/739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 4.1544e-05 - val_loss: 1.5273e-05 - learning_rate: 6.1035e-08\n","[hourly] CHAINLINK_INR: done. val_RMSE=17.8814 test_RMSE=26.4654\n","[hourly] Training DOGECOIN_INR...\n","[hourly] DOGECOIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 5.0166e-05 - val_loss: 3.5208e-05 - learning_rate: 4.8828e-07\n","Epoch 2/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 4.3179e-05 - val_loss: 3.5254e-05 - learning_rate: 4.8828e-07\n","Epoch 3/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1454e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 4.1465e-05 - val_loss: 3.5245e-05 - learning_rate: 4.8828e-07\n","Epoch 4/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 4.5525e-05 - val_loss: 3.5222e-05 - learning_rate: 2.4414e-07\n","Epoch 5/50\n","\u001b[1m454/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0726e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 5.0691e-05 - val_loss: 3.5208e-05 - learning_rate: 2.4414e-07\n","Epoch 6/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 4.5686e-05 - val_loss: 3.5228e-05 - learning_rate: 1.2207e-07\n","Epoch 7/50\n","\u001b[1m456/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6974e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 4.6973e-05 - val_loss: 3.5213e-05 - learning_rate: 1.2207e-07\n","Epoch 8/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - loss: 4.6464e-05 - val_loss: 3.5215e-05 - learning_rate: 6.1035e-08\n","Epoch 9/50\n","\u001b[1m455/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.3932e-05\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 4.3967e-05 - val_loss: 3.5217e-05 - learning_rate: 6.1035e-08\n","Epoch 10/50\n","\u001b[1m458/458\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 4.9841e-05 - val_loss: 3.5216e-05 - learning_rate: 3.0518e-08\n","[hourly] DOGECOIN_INR: done. val_RMSE=0.3770 test_RMSE=0.3267\n","[hourly] Training ETHEREUM_INR...\n","[hourly] ETHEREUM_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 4.1037e-05 - val_loss: 1.1897e-05 - learning_rate: 2.5000e-04\n","Epoch 2/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 4.1031e-05 - val_loss: 2.0415e-05 - learning_rate: 2.5000e-04\n","Epoch 3/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.8518e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 3.8518e-05 - val_loss: 1.3500e-05 - learning_rate: 2.5000e-04\n","Epoch 4/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 3.5080e-05 - val_loss: 1.4294e-05 - learning_rate: 1.2500e-04\n","Epoch 5/50\n","\u001b[1m994/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.5513e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 3.5509e-05 - val_loss: 1.4712e-05 - learning_rate: 1.2500e-04\n","Epoch 6/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 3.2194e-05 - val_loss: 1.1762e-05 - learning_rate: 6.2500e-05\n","Epoch 7/50\n","\u001b[1m996/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.1766e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 3.1766e-05 - val_loss: 1.0103e-05 - learning_rate: 6.2500e-05\n","Epoch 8/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 3.0419e-05 - val_loss: 1.4957e-05 - learning_rate: 3.1250e-05\n","Epoch 9/50\n","\u001b[1m994/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8172e-05\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.8176e-05 - val_loss: 9.6772e-06 - learning_rate: 3.1250e-05\n","Epoch 10/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.7075e-05 - val_loss: 9.7719e-06 - learning_rate: 1.5625e-05\n","Epoch 11/50\n","\u001b[1m992/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.7488e-05\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 2.7491e-05 - val_loss: 9.4956e-06 - learning_rate: 1.5625e-05\n","Epoch 12/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.8218e-05 - val_loss: 9.5151e-06 - learning_rate: 7.8125e-06\n","Epoch 13/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7929e-05\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.7928e-05 - val_loss: 9.4318e-06 - learning_rate: 7.8125e-06\n","Epoch 14/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.6919e-05 - val_loss: 9.9938e-06 - learning_rate: 3.9063e-06\n","Epoch 15/50\n","\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6513e-05\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.6514e-05 - val_loss: 9.6663e-06 - learning_rate: 3.9063e-06\n","Epoch 16/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.5491e-05 - val_loss: 9.3772e-06 - learning_rate: 1.9531e-06\n","Epoch 17/50\n","\u001b[1m993/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5879e-05\n","Epoch 17: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.5882e-05 - val_loss: 9.3762e-06 - learning_rate: 1.9531e-06\n","Epoch 18/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 2.7060e-05 - val_loss: 9.3566e-06 - learning_rate: 9.7656e-07\n","Epoch 19/50\n","\u001b[1m996/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5919e-05\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.5919e-05 - val_loss: 9.3503e-06 - learning_rate: 9.7656e-07\n","Epoch 20/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.6806e-05 - val_loss: 9.3594e-06 - learning_rate: 4.8828e-07\n","Epoch 21/50\n","\u001b[1m994/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.5968e-05\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.5969e-05 - val_loss: 9.3473e-06 - learning_rate: 4.8828e-07\n","Epoch 22/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 2.6360e-05 - val_loss: 9.3460e-06 - learning_rate: 2.4414e-07\n","Epoch 23/50\n","\u001b[1m992/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6363e-05\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - loss: 2.6363e-05 - val_loss: 9.3456e-06 - learning_rate: 2.4414e-07\n","Epoch 24/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 2.7755e-05 - val_loss: 9.3427e-06 - learning_rate: 1.2207e-07\n","Epoch 25/50\n","\u001b[1m994/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.4962e-05\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.4965e-05 - val_loss: 9.3437e-06 - learning_rate: 1.2207e-07\n","Epoch 26/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.6260e-05 - val_loss: 9.3447e-06 - learning_rate: 6.1035e-08\n","Epoch 27/50\n","\u001b[1m994/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5095e-05\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.5099e-05 - val_loss: 9.3433e-06 - learning_rate: 6.1035e-08\n","Epoch 28/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.6706e-05 - val_loss: 9.3436e-06 - learning_rate: 3.0518e-08\n","Epoch 29/50\n","\u001b[1m991/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6389e-05\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 1.525878978725359e-08.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.6393e-05 - val_loss: 9.3425e-06 - learning_rate: 3.0518e-08\n","Epoch 30/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.6343e-05 - val_loss: 9.3417e-06 - learning_rate: 1.5259e-08\n","Epoch 31/50\n","\u001b[1m996/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6423e-05\n","Epoch 31: ReduceLROnPlateau reducing learning rate to 7.629394893626795e-09.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 2.6422e-05 - val_loss: 9.3416e-06 - learning_rate: 1.5259e-08\n","Epoch 32/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.5752e-05 - val_loss: 9.3416e-06 - learning_rate: 7.6294e-09\n","Epoch 33/50\n","\u001b[1m993/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6043e-05\n","Epoch 33: ReduceLROnPlateau reducing learning rate to 3.814697446813398e-09.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.6044e-05 - val_loss: 9.3413e-06 - learning_rate: 7.6294e-09\n","Epoch 34/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.6289e-05 - val_loss: 9.3413e-06 - learning_rate: 3.8147e-09\n","Epoch 35/50\n","\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.6522e-05\n","Epoch 35: ReduceLROnPlateau reducing learning rate to 1.907348723406699e-09.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.6521e-05 - val_loss: 9.3412e-06 - learning_rate: 3.8147e-09\n","Epoch 36/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - loss: 2.6102e-05 - val_loss: 9.3412e-06 - learning_rate: 1.9073e-09\n","Epoch 37/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5921e-05\n","Epoch 37: ReduceLROnPlateau reducing learning rate to 9.536743617033494e-10.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.5921e-05 - val_loss: 9.3412e-06 - learning_rate: 1.9073e-09\n","Epoch 38/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 10ms/step - loss: 2.7008e-05 - val_loss: 9.3413e-06 - learning_rate: 9.5367e-10\n","Epoch 39/50\n","\u001b[1m995/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6398e-05\n","Epoch 39: ReduceLROnPlateau reducing learning rate to 4.768371808516747e-10.\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.6397e-05 - val_loss: 9.3413e-06 - learning_rate: 9.5367e-10\n","Epoch 40/50\n","\u001b[1m997/997\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.6792e-05 - val_loss: 9.3413e-06 - learning_rate: 4.7684e-10\n","[hourly] ETHEREUM_INR: done. val_RMSE=1318.3612 test_RMSE=2990.2144\n","[hourly] Training LITECOIN_INR...\n","[hourly] LITECOIN_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 10ms/step - loss: 2.2520e-05 - val_loss: 3.8387e-06 - learning_rate: 4.8828e-07\n","Epoch 2/50\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 2.2546e-05 - val_loss: 3.7946e-06 - learning_rate: 4.8828e-07\n","Epoch 3/50\n","\u001b[1m1184/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2690e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 2.2690e-05 - val_loss: 3.8064e-06 - learning_rate: 4.8828e-07\n","Epoch 4/50\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 2.4294e-05 - val_loss: 3.7843e-06 - learning_rate: 2.4414e-07\n","Epoch 5/50\n","\u001b[1m1184/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3544e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 2.3543e-05 - val_loss: 3.7938e-06 - learning_rate: 2.4414e-07\n","Epoch 6/50\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - loss: 2.2368e-05 - val_loss: 3.7855e-06 - learning_rate: 1.2207e-07\n","Epoch 7/50\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2.2820e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 9ms/step - loss: 2.2820e-05 - val_loss: 3.7909e-06 - learning_rate: 1.2207e-07\n","Epoch 8/50\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 2.2979e-05 - val_loss: 3.7918e-06 - learning_rate: 6.1035e-08\n","Epoch 9/50\n","\u001b[1m1181/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3062e-05\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n","\u001b[1m1185/1185\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - loss: 2.3061e-05 - val_loss: 3.7853e-06 - learning_rate: 6.1035e-08\n","[hourly] LITECOIN_INR: done. val_RMSE=69.7129 test_RMSE=93.7633\n","[hourly] Training POLKADOT_INR...\n","[hourly] POLKADOT_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - loss: 6.1117e-05 - val_loss: 3.8123e-06 - learning_rate: 1.9531e-06\n","Epoch 2/50\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - loss: 5.8202e-05 - val_loss: 3.8073e-06 - learning_rate: 1.9531e-06\n","Epoch 3/50\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.9540e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 5.9543e-05 - val_loss: 3.8022e-06 - learning_rate: 1.9531e-06\n","Epoch 4/50\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - loss: 5.8027e-05 - val_loss: 3.8298e-06 - learning_rate: 9.7656e-07\n","Epoch 5/50\n","\u001b[1m600/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.1981e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 6.1975e-05 - val_loss: 3.8545e-06 - learning_rate: 9.7656e-07\n","Epoch 6/50\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - loss: 5.9914e-05 - val_loss: 3.8269e-06 - learning_rate: 4.8828e-07\n","Epoch 7/50\n","\u001b[1m603/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8289e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 5.8300e-05 - val_loss: 3.8450e-06 - learning_rate: 4.8828e-07\n","Epoch 8/50\n","\u001b[1m606/606\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 6.1615e-05 - val_loss: 3.8176e-06 - learning_rate: 2.4414e-07\n","[hourly] POLKADOT_INR: done. val_RMSE=9.2719 test_RMSE=8.8853\n","[hourly] Training POLYGON_INR...\n","[hourly] POLYGON_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - loss: 6.9241e-05 - val_loss: 1.4599e-05 - learning_rate: 4.8828e-07\n","Epoch 2/50\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 7.3328e-05 - val_loss: 1.4585e-05 - learning_rate: 4.8828e-07\n","Epoch 3/50\n","\u001b[1m607/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.2408e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 7.2405e-05 - val_loss: 1.4593e-05 - learning_rate: 4.8828e-07\n","Epoch 4/50\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - loss: 7.5278e-05 - val_loss: 1.4621e-05 - learning_rate: 2.4414e-07\n","Epoch 5/50\n","\u001b[1m608/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.1676e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - loss: 7.1684e-05 - val_loss: 1.4648e-05 - learning_rate: 2.4414e-07\n","Epoch 6/50\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 6.9633e-05 - val_loss: 1.4631e-05 - learning_rate: 1.2207e-07\n","Epoch 7/50\n","\u001b[1m610/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.2233e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m611/611\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - loss: 7.2232e-05 - val_loss: 1.4625e-05 - learning_rate: 1.2207e-07\n","[hourly] POLYGON_INR: done. val_RMSE=0.9641 test_RMSE=0.5601\n","[hourly] Training RIPPLE_INR...\n","[hourly] RIPPLE_INR: Resuming training from saved checkpoint...\n","Epoch 1/50\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 1.8775e-05 - val_loss: 3.6487e-06 - learning_rate: 2.4414e-07\n","Epoch 2/50\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.0002e-05 - val_loss: 3.6526e-06 - learning_rate: 2.4414e-07\n","Epoch 3/50\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0407e-05\n","Epoch 3: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.0407e-05 - val_loss: 3.6483e-06 - learning_rate: 2.4414e-07\n","Epoch 4/50\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - loss: 1.9640e-05 - val_loss: 3.6562e-06 - learning_rate: 1.2207e-07\n","Epoch 5/50\n","\u001b[1m841/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0806e-05\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 2.0804e-05 - val_loss: 3.6563e-06 - learning_rate: 1.2207e-07\n","Epoch 6/50\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 10ms/step - loss: 2.0137e-05 - val_loss: 3.6533e-06 - learning_rate: 6.1035e-08\n","Epoch 7/50\n","\u001b[1m839/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1509e-05\n","Epoch 7: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - loss: 2.1505e-05 - val_loss: 3.6523e-06 - learning_rate: 6.1035e-08\n","Epoch 8/50\n","\u001b[1m842/842\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - loss: 2.0007e-05 - val_loss: 3.6534e-06 - learning_rate: 3.0518e-08\n","[hourly] RIPPLE_INR: done. val_RMSE=0.6062 test_RMSE=2.6857\n","[hourly] Metrics saved -> /content/drive/MyDrive/infosys/outputs/metrics/hourly/metrics.csv\n","Done.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nforAG-Rl6FU"},"execution_count":null,"outputs":[]}]}